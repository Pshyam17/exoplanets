# -*- coding: utf-8 -*-
"""Nasa Space Apps Challenge - DLM

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13Osy7Za-N9D9rZ1ediv7EO1I-LW4nHx0
"""

#from google.colab import drive
#drive.mount('/content/drive')

# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot as plt
import seaborn as sns

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All"
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

#!pip install tensorflow --quiet # scikit-learn pandas numpy seaborn

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.impute import SimpleImputer
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# 1. Load the dataset
koi_table = pd.read_csv("/kaggle/input/kepler-and-tess-exoplanet-data/q1_q8_koi_2025.02.03_04.12.15.csv", skiprows=1, delimiter=",", comment="#")

# 2. Feature Engineering (Insolation Flux) - Add this if you want to use it
koi_table['koi_insol'] = koi_table['koi_steff']**4 / koi_table['koi_period']**2  # Simplified formula

# 3. Define Features (including insolation flux)
features = ["koi_period", "koi_prad", "koi_teq", "koi_srad", "koi_slogg", "koi_steff", "koi_insol"] # Include koi_steff, koi_insol
# features = ["koi_period", "koi_prad", "koi_teq", "koi_srad", "koi_slogg", "koi_steff"] # If you don't want koi_insol

# 4. Map labels
koi_table["label"] = koi_table["koi_disposition"].map({"CONFIRMED": 1, "FALSE POSITIVE": 0, "CANDIDATE":1}) # Include CANDIDATE as 1

# 5. Impute missing values (using SimpleImputer)
imputer = SimpleImputer(strategy='mean')  # Or 'median'
koi_table[features] = imputer.fit_transform(koi_table[features])

# 6. Drop rows with missing labels (if any)
koi_table = koi_table.dropna(subset=["label"])

# 7. Prepare data for ML
X = koi_table[features]
y = koi_table["label"]

# Split into training (80%) and testing (20%)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Normalize the data
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Build Neural Network Model
model = Sequential([
    Dense(64, activation="relu", input_shape=(X_train.shape[1],)),  # First hidden layer (64 neurons)
    Dropout(0.3),  # Prevent overfitting
    Dense(32, activation="relu"),  # Second hidden layer (32 neurons)
    Dropout(0.3),  # Another dropout layer
    Dense(16, activation="relu"),  # Third hidden layer (16 neurons)
    Dense(1, activation="sigmoid")  # Output layer (Sigmoid for binary classification)
])

# Compile the model
model.compile(optimizer="adam", loss="binary_crossentropy", metrics=["accuracy"])

# Model summary
model.summary()

# Train the model
history = model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_data=(X_test_scaled, y_test))

# Evaluate on test data
test_loss, test_acc = model.evaluate(X_test_scaled, y_test)
print(f"\nTest Accuracy: {test_acc:.2f}")

# Predict labels
y_pred = (model.predict(X_test_scaled) > 0.5).astype("int32")

# Print classification report
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

# Plot Confusion Matrix
plt.figure(figsize=(6,5))
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt="d", cmap="Blues", xticklabels=["False Positive", "Confirmed"], yticklabels=["False Positive", "Confirmed"])
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Neural Network Confusion Matrix")
plt.show()

# Plot training history
plt.figure(figsize=(12, 5))

# Loss Plot
plt.subplot(1,2,1)
plt.plot(history.history["loss"], label="Train Loss")
plt.plot(history.history["val_loss"], label="Val Loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend()
plt.title("Model Loss Over Epochs")

# Accuracy Plot
plt.subplot(1,2,2)
plt.plot(history.history["accuracy"], label="Train Accuracy")
plt.plot(history.history["val_accuracy"], label="Val Accuracy")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.title("Model Accuracy Over Epochs")

plt.show()

toi_table = pd.read_csv("/kaggle/input/kepler-and-tess-exoplanet-data/TOI_2025.02.03_06.18.31.csv",
                         skiprows=1, delimiter=",", comment="#")

# 3. Define Feature Mapping (same as before)
feature_mapping = {
    "koi_period": "pl_orbper",
    "koi_prad": "pl_rade",
    "koi_teq": "pl_eqt",
    "koi_srad": "st_rad",
    "koi_slogg": "st_logg",
    "koi_steff": "st_teff",
    "koi_insol": "pl_insol"
}


toi_features = []
for koi_feature, toi_feature in feature_mapping.items():
    if toi_feature in toi_table.columns:
        toi_features.append(toi_feature)
    else:
        print(f"Warning: TOI table does not have a column matching '{koi_feature}'. Skipping.")

print("Using TOI features:", toi_features)

# 4. Prepare new data (using the mapped names)
new_data = toi_table[toi_features].copy()

# 5. Rename columns in new_data to match the training data features
reverse_mapping = {v: k for k, v in feature_mapping.items()}  # Create reverse mapping
new_data = new_data.rename(columns=reverse_mapping)  # Rename columns

# 6. Impute missing values (if any)
imputer_toi = SimpleImputer(strategy='mean')  # Or keep the same imputer if you prefer.
new_data[features] = imputer_toi.fit_transform(new_data[features])

# 7. Scale the new data (using the SAME scaler)
new_data_scaled = scaler.transform(new_data)  # Now the feature names should match!


# Predict using trained model
predictions = (model.predict(new_data_scaled) > 0.5).astype("int32")

# Add predictions to DataFrame
toi_table["Predicted Label"] = predictions

# 10. Display results (adapt column names as needed)
print(toi_table[toi_table["Predicted Label"] == 1][["toi", "pl_rade", "pl_orbper"]])  # Adapt column names

# Save the modified TOI table with predictions
output_file = "toi_predictions.csv"
toi_table.to_csv(output_file, index=False)
print(f"Data saved to '{output_file}'.")

# Load the saved DataFrame
import pandas as pd

new_toi_table = pd.read_csv("toi_predictions.csv")
print("Data reloaded successfully. Here's a sample:")
print(new_toi_table.head())

new_toi_table.head()

# Plot 1: Bar Plot for Prediction Distribution
plt.figure(figsize=(8, 5))
sns.countplot(x="Predicted Label", data=new_toi_table, palette="coolwarm")
plt.title("Distribution of Predicted Labels")
plt.xlabel("Predicted Label (0 = Not Exoplanet, 1 = Exoplanet)")
plt.ylabel("Count")
plt.show()

# 2. Distribution of TOI values
plt.figure(figsize=(8, 6))
sns.histplot(new_toi_table['toi'], kde=True)  # Added KDE for smoother visualization
plt.title('Distribution of TOI Values')
plt.xlabel('TOI Value')
plt.ylabel('Frequency')
plt.show()

"""### ü™ê **Visualizations** üöÄ  

---

#### **2Ô∏è‚É£ Distribution of TOI Values**  
- This plot shows the frequency of TOI (TESS Object of Interest) values across the dataset.  
- The **KDE (Kernel Density Estimation)** overlay highlights the smooth distribution pattern of TOIs, helping to visualize regions with dense occurrences of objects.
"""

# 3. Relationship between TOI and Predicted Label (using boxplot)
plt.figure(figsize=(8, 6))
sns.boxplot(x='Predicted Label', y='toi', data=new_toi_table)
plt.title('TOI vs. Predicted Label')
plt.xlabel('Predicted Label')
plt.ylabel('TOI Value')
plt.show()

"""---

#### **3Ô∏è‚É£ Relationship Between TOI and Predicted Label**  
- The **boxplot** shows how the TOI values vary across prediction categories (`Predicted Label = 0` for non-exoplanet and `1` for exoplanet candidates).  
- This visualization helps detect whether TOI values show distinct distributions for predicted exoplanets.
"""

# 4. Distribution of 'tfopwg_disp' (using bar chart for counts)
plt.figure(figsize=(10, 6)) # Increased figure size for better readability
sns.countplot(x='tfopwg_disp', data=new_toi_table)
plt.title('Distribution of tfopwg_disp')
plt.xlabel('tfopwg_disp Category')
plt.ylabel('Number of TOIs')
plt.xticks(rotation=45, ha='right') # Rotate x-axis labels if needed
plt.tight_layout() # Adjust layout to prevent labels from overlapping
plt.show()

"""---

#### **4Ô∏è‚É£ Distribution of `tfopwg_disp` Categories**  
- The bar chart counts different categories within `tfopwg_disp`, representing the classification status (`PC`, `FP`, or other values).  
- This plot is useful for identifying biases or imbalances in status categories.
"""

# 5. Scatter plot of ra and dec, colored by Predicted Label
plt.figure(figsize=(8, 6))
sns.scatterplot(x='ra', y='dec', hue='Predicted Label', data=new_toi_table, s=20) # Smaller markers for clarity
plt.title('RA vs. Dec (Colored by Predicted Label)')
plt.xlabel('Right Ascension (ra)')
plt.ylabel('Declination (dec)')
plt.show()

"""---

#### **5Ô∏è‚É£ Scatter Plot of RA (Right Ascension) vs Dec (Declination)**  
- This scatter plot visualizes the spatial distribution of TOIs on the celestial sphere, colored by their predicted exoplanet classification.  
- The spatial grouping may reveal whether predicted exoplanets cluster in specific sky regions.
"""

# 6. Distribution of st_logg (using histogram)
plt.figure(figsize=(8, 6))
sns.histplot(new_toi_table['st_logg'], kde=True)
plt.title('Distribution of st_logg')
plt.xlabel('log g')
plt.ylabel('Frequency')
plt.show()

"""---

#### **6Ô∏è‚É£ Distribution of `st_logg` Values**  
- This plot displays the distribution of stellar surface gravity (`st_logg`) values for TOIs, with a KDE curve showing a smooth estimate of the distribution.  
- Peaks in the plot may indicate preferred surface gravities for host stars.
"""

# 7. Correlation heatmap (for numerical columns) - Optional but useful
# Select numerical columns for correlation calculation
numerical_cols = new_toi_table.select_dtypes(include=['number'])

# Calculate the correlation matrix
correlation_matrix = numerical_cols.corr()

plt.figure(figsize=(12, 10)) # Increased figure size for better readability
sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm') # annot=True to display correlation values
plt.title('Correlation Heatmap')
plt.show()

"""---

#### **7Ô∏è‚É£ Correlation Heatmap**  
- The heatmap visualizes correlations between numerical features in the dataset.  
- Darker colors represent negative correlations, while lighter shades indicate positive correlations.  
- Useful for detecting strong relationships (e.g., between stellar parameters or orbital properties).
"""

# 8. Time series plot of TOI creation (if the 'toi_created' column is in datetime format)
try:
    new_toi_table['toi_created'] = pd.to_datetime(new_toi_table['toi_created'])
    plt.figure(figsize=(10, 6))
    plt.plot(new_toi_table['toi_created'], new_toi_table.index) #Plotting index to show time series of TOIs
    plt.title('TOI Creation Over Time')
    plt.xlabel('Date')
    plt.ylabel('TOI Index')
    plt.show()
except KeyError:
    print("toi_created column not found or not in datetime format.")
except Exception as e:
    print(f"An error occurred during time series plotting: {e}")

"""---

#### **8Ô∏è‚É£ Time Series Plot of TOI Creation Over Time**  
- This plot shows the evolution of TOI entries over time.  
- By mapping TOI creation dates to their indices, it reveals trends in TOI detections and model predictions.  

"""
